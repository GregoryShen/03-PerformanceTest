# 张挺知乎live

## 引子-为什么要学性能测试

本次 live 主要介绍了性能测试的入门基础知识. 从理论开始讲到实践, 从原理上讲解性能测试到底是怎么回事. 与我们在网上能看到的大量讲性能测试工具的资料不同, 本 live 相较于怎么做更关注为什么这样做. 同时, 本 live 也关注并满足了最普遍的需求: 新人应该怎样在知识储备不足, 赶鸭子上架的情况下做性能测试? 会对这种情况下的处理方法做重点讲解

### 概述

1. 引子-为什么要学性能测试
2. 性能测试的基本原理
   1. Web性能测试的示意图
   2. 请求结果与监控结果
   3. 单次结果与统计结果
   4. 主要统计结果及其计算
3. 赶鸭子上架的性能测试怎么做
4. 性能测试场景设计策略
5. 赶鸭子上架的性能调优怎么做

### 为什么要学性能测试

1. 项目中往往不存在专职性能测试人员

2. 提高对系统的整体理解

3. 多维度思考系统质量,而非单纯功能角度

4. 转变自身角色

   我们作为测试人员并不仅仅是完成黑盒测试, 理解这个系统是怎样工作的

### 性能测试想做什么 - 尽可能模拟真实业务场景

UI泛指浏览器、移动app、桌面app、无图形界面的各种接口等

服务端泛指处理请求的服务器及他背后可能存在的很多很多服务器

上图是一个简化过的web性能测试的示意图,性能测试时尽可能用接近生产环境的专门环境来测试,即使如此仍然不能做到与生产环境完全相同,因此只能做估算和参考.

## 性能测试的基本原理

1. 模拟各种业务场景下的负载压力

   负载压力就是比如说我发很多请求或者说打开很多网页这就是负载的压力, 或者有很多用户同时做登录. 看你具体业务, 只不过是单个人做这种业务可能负载压力不大, 但是很多人做这个业务负载压力就会变大, 所以就要用工具去模拟

2. 观察压力下服务端业务逻辑处理是否正常

   单用户做一个操作可能是正常的, 假设百万个用户同时做这个操作可能业务逻辑处理可能就会出错, 所以就是观察在压力下服务端业务逻辑处理是不是正常, 压力可能是不同的压力下要观察

3. 观察压力下服务端资源使用状况是否吃紧

   服务端有什么资源, 比如服务器是一台电脑, 电脑有CPU、内存、硬盘、网络, 这些都是有资源的一些指标, 比如CPU使用率,一开始是1% 2%,用户数量上来了,压力上来了,可能是50% 60% 这个时候同时它的业务逻辑, 导致业务逻辑可能会出错 

4. 改变模拟的压力来重复上述观察

   通过改变模拟的压力, 可以模拟小压力或者大压力来重复上面的官擦好.可以改变小压力

别的观察主要有服务端软件层次的观察. 当然这个也可以包含在业务逻辑里面.

一个简单的性能测试的基本流程:得到性能测试结果

性能测试结果由<u>请求结果</u>与<u>服务端监控结果</u>组成

<u>请求结果</u>包括响应时间、返回值等**<u>单次请求的响应里找到的结果</u>**以及他们对应的<u>统计结果</u>

请求结果: ==通过解析服务端对请求的响应直接得到的结果==, 如响应时间、响应的http状态码、响应体内容、单个响应包含的数据量等.此外==还可以通过自定义逻辑间接得到一些复杂的请求结果==.(比如一个无论如何都返回200的接口, 其真实成功与否由响应体内某字段决定)

有一些请求结果是要做一些比较复杂的逻辑运算的. 

==请求结果是一个一个互相独立的结果, 每个请求有自己的请求结果==

自定义的逻辑, 然后按照开发, 一些请求结果是要做一些比较复杂的逻辑运算的. 互相独立的结果. 比如测试发了1000个请求结果, 还有500个是失败了. 这就是请求结果, 他是一个一个互相独立的测试结果.

<u>服务端监控结果</u>包括<u>服务端各项资源使用率及数据量</u>等统计结果

服务端监控结果:==一段时间内==的CPU的负载, CPU使用率、网络数据传输量、内存的占用率、IO数据量==等指标变化的情况==

发包的工具, 用来发包, 发给右边的服务器, 服务器给他一个返回值, 可以解析出来响应时间、错误率等指标, 右边服务端上我们装了一个监控器, 也有可能是云平台提供的, 比如 C

服务端监控结果是随着时间线不断变化的指标, 这一段时间内所有请求和响应共同造成了这个结果. 图中例子在11:30附近CPU占用率100%,表示到了性能瓶颈, 出图原理在时间线上各个时间点x坐标标识出对应的指标y坐标, 然后连成线, 所以图中11:00 到11:15中间由一小段同一个x上两个y上不可能的

### 单次结果与统计结果的区别举例:

**单次结果**: 调用正确/调用错误

**统计结果**: <u>持续调用n小时或n</u>次, 其中调用正确比例`x%`, 叫做<u>正确率</u>`x%`或错误率`(1-x%)`

以此类推, 单次结果的维度可以很多, 不局限于正确率错误率, 比如, 单次结果中返回的http代码是200, 404, 500, 对应的统计结果是200比例x%, 404比例y%, 500比例z%, 要统计哪些单次结果?由具体业务决定, <u>统计结果还包括通过对统计结果进行计算得到的新的统计结果.</u>



### 主要统计结果及其计算

**(总)并发用户数**: 同一时间在系统上的用户数量, 这些用户可能分布在不同的功能模块或页面上

**(总)并发请求数**: 同一时间在系统上的用户同时向服务器作出的请求数量, 这些请求也可能分布在不同的功能模块或页面上.

同一时间一个用户可能只给系统发一个请求, 也可能给系统发100个请求, 所以, 下次有人告诉你系统要支持多少并发的时候, 问清楚上并发用户数还是并发请求数(这两个数字可能差很多)

**吞吐量(平均吞吐量)**: 吞吐量表示待测应用对业务的支持量, 以TPS或QPS为单位, 表示每秒钟能处理的请求数

**平均响应时间**: 一些请求从发起到收到服务端响应所需的时间的平均数
$$
一段时间内的请求平均响应时间 = \dfrac{单个请求的响应时间之和(秒)}{这段时间内服务端处理掉的总请求数(个)}
$$

$$
一段时间内的平均吞吐量 = \dfrac{这段时间内服务端处理掉的总请求数(个)}{时间(秒)}
$$

> 单位名称是(TPS, transaction per second) 或 (QPS, Query per second)

设这段时间内服务端处理掉的总请求数(个)为n, 这段时间为t(秒), 一段时间内的请求平均响应时间为Tv(秒), 一段时间内的平均吞吐量为Qv, 单个响应的响应时间为Ts, SUM为求和函数. 则 

$$
Tv = \dfrac{\sum{Ts}}{n}
$$

$$
Qv = \dfrac{n}{t}
$$

由公式1与公式2推导出:

```
Qv = SUM(Ts)/Tv/t
```

`Qv = SUM(Ts)t/Tv` — 公式3

由公式3得: 平均吞吐量`Qv`与平均响应时间`Tv`成反比.

即: ==平均响应时间越长, 则平均吞吐量越小==.

这个推导是符合逻辑的, 当服务器硬件性能固定时:

1. 假设服务端只提供数据量极小的静态页面, 没有任何业务逻辑, 只需要处理0.1毫秒, 那么服务端可以每秒钟同时处理极大数量的请求, 那么吞吐量就高
2. 假设服务端收到每个请求都要处理1小时才给响应, 那么服务端每小时才能处理1个请求, 吞吐量就极低.

这个推导结果主要说明了两个问题:

1. 性能测试关键指标吞吐量与具体业务密切相关, 因此设计性能测试不能脱离具体业务.这一点会直接影响性能测试工具的设计与挑选
2. 不同业务的服务端, 无法通过对比吞吐量来判断谁的性能强.业务耗时小的服务器的吞吐量显然会比业务耗时大大服务器的吞吐量高.同理,并发请求数高也不能代表牛逼. 因为只有项目参与人员才知道这高并发背后的业务到底是简单业务还是复杂业务. 简单业务的高并发搞不好还是复杂业务的低一点的并发更难、要求更高. 因此有些公司在jd里吹牛逼说这个项目要处理高并发多厉害能让人学到东西, 到底有多厉害还是很难说的. 另外, 得益于基础设施的技术发展, 云计算平台的发展, 高并发也越来越容易实现了.

错误率: 一段时间内出错请求个数(个)/总请求数(个)

什么叫出错的请求?

1. 没有任何响应的请求 — 超时
2. 有响应,但卡了很久才给响应 — 超时
3. 有响应,响应代码不是预期值 — 断言错误
4. 有响应,响应代码是预期值.但响应体内有数据不是预期值 — 断言错误

超时请求的影响:

==公式1==:

一段时间内的请求平均响应时间 = 单个请求的响应时间之和(秒) / 这段时间内服务端处理掉的总请求数(个)

因为公式1中单个请求的响应时间之和(秒)很不幸地包含了超时请求, 因而超时请求的响应时间会导致平均响应十斤啊不能反映大多数请求的响应时间.

如下例子:

10个响应中9个都是1秒钟拿到响应, 1个卡了99秒才拿到响应, 那么根据公式1, 平均响应时间 = (9*1+99)/10=10秒,但实际上大多数请求(90%的请求)的响应时间都是1秒, 因此引出了新的统计结果: ==90%平均响应时间==

**<u>90%平均响应时间</u>**: 从平均响应时间计算时所统计的那些请求里, 去掉响应时间最长的10%的请求后, 剩余的请求计算出来的平均响应时间.

90%平均响应时间有效地排除了个别超时请求对平均响应时间的影响, 因此而使数据更接近真实业务场景的反映. 同理还有80%平均响应时间, 70%…等等

在jmeter等一些性能测试工具中, 往往可以直接显示x%平均响应时间这种指标, 可见这个指标的通用性.

**<u>数据吞吐量/平均传输带宽</u>**: 这个指标用于计算服务端的数据传输量

在一些重数据传输的性能测试场景中, 我们需要监控和计算这个指标

顺便讲一下数据传输的单位: kbps(千比特每秒), 又称千比特率, 指的是数字信号的传输速率, 也就是每秒钟传送多少个千位的信息(k表示千, kb表示的是多少千个位), 也可以表示网络的传输速度, 为了在直观上显得网络的传输速度较快, 一般公司都使用kb(千位)来表示, 如果是大写的B的KBps, 则表示每秒传送多少个千字节.

1kByte/s=8kbit/s(一般简写为1KB/s=8kb/s)

根据业务的不同, 单位名称会变大, 比如:

1MB=1,024KB=1,024 \* 1,024b=1048576b

MB上面还有GB, TB, PB

我曾经测过跨过数据库同步业务的压测项目, 要求平均传输带宽达到GB级.

具体要求多少传输带宽, 我们也是根据**实际数据库大小/能接受的时间**来算出来的.

## 赶鸭子上架的性能测试怎么做

马上就要“我”搞性能测试, 但是“我”没做过, 也不会做性能测试, 公司里也没有人会做, 时间紧迫了, 现在怎么办?

首先根据性能测试基本原理, 我们要模拟各种业务场景下的负载压力. 因此:

1. **<u>90%平均响应时间</u>**. 比如有些不常用的用户注册场景可能不需要做压测.
2. <u>由熟悉业务的人士, **估算**其并发用户数, 再由熟悉业务的人士和熟悉技术实现的人士一起**估算**</u>这个并发用户数的并发请求数, 注意, 很多系统的负载都有**平时**和**高峰**的区分, 比如12306平时用的人不太多, 但春运订票高<u>峰时并发用户数与并发请求数都会暴涨</u>.假设系统平时有一千人同时在线, 每天高峰时段有三千人现在活每年高峰月份的高峰时段有五千人同时在线
3. 然后就要考虑这次性能测试所用的环境大概能支持多少用户, 这个环境和生产环境的区别: 假如这个环境能支持x个用户, 那么生产应该可以支持y个用户. 最好估算出这样的x和y的关系. 然后, 假设x个用户的请发请求数数n,测试中还要留出缓冲风险的时间, 那么希望达到的并发请求数可以是n的1.1倍到1.5倍, 具体几倍后面测完了再说. 最后就是测出来支持xxx用户, 领导来说拍板说行不行, 够不够, 重点是**建立这个性能测试环境可能需要开发和运维等人帮忙.** 尽量搞个独立的环境.
4. 然后, 对1里列出的业务场景做具体的测试场景设计.
5. 对1里列出的业务场景做具体的测试脚本实现. 脚本实现最简单的就是jmeter录制脚本, 然后做参数化, 加检查点. 照着jmeter用户手册学习一两天就能上手.
6. 对1里列出的业务场景做具体的测试脚本执行. 执行的时候需要做好服务端监控. 还记得我们前面列过需要监控的指标吧, 包括但不限于那些指标. 因为是赶鸭子上架不会做, 怎么办, 找运维活开发一起做, 你这边跑脚本, 那边让他们盯着看指标正常不正常, 自己盯着当然也行.
7. 进入调优环节.
8. 给出测试报告, 汇总整个测试过程, 给出各种性能指标.

## 性能测试场景设计策略

1. 基线测试baseline testing: 

   单用户跑一遍, 此时的性能测试结果会作为后续的对比依据.

2. 性能测试performance testing: 

   逐步增加并发请求数比如10个,20个, 50个,80个,130个,得到不同并发请求数情况下的性能测试结果变化趋势图.这个图里常常可以发现性能瓶颈.比如用户数到某个值时突然性能指标下降了很多, 错误率大幅上升了, 那就需要进一步分析是软件的问题还是硬件的问题, 还是环境的问题等. 这里, 并发请求数要一直驾到之前预估过的测试环境需要支持的最大数字.

3. 压力测试load testing: 

   使用超过系统设计的最大用户数, 看看待测应用会不会崩溃, 崩溃后会怎么样, 有没有隐患和风险等, 比如数据大量丢失之类, 崩溃后无法恢复等都是大问题.

4. 稳定性测试stability testing

   在较高负载下, 做较长时间的测试, 来观察系统的稳定性

5. 静态测试static testing

   对某静态网页做性能测试, 保证错误率低且吞吐量高, 用来验证网络硬件设置正确.

此外还要在每种场景都考虑测试预期结果:

之前说过的各种测试结果和其计算结果需要在这里设计好, 其值的合理范围.

比如, 请求正确率>95%, 90%平均响应时间< 1000ms等

还要设计每个场景的具体数据. 比如稳定性测试准备做两次, 一次做72小时, 使用性能测试时测出来的能支持的最大用户数的80%. 另一次做140小时, 使用40%的最大用户数.

## 赶鸭子上架的性能调优怎么做

首先, “一个人”是做不了的,除非你是传说中的“性能专家”.

然后, 我们需要团队合作, 测试人员来牵头, 找开发、运维、架构、DBA、基础设施提供商的技术支持等角色一起做调优.

如下图, 测试人员最基本的就是做到“那个谁,你再跑一遍测试”的时候, 可以点一下测试脚本让它再运行一遍, 然后把问题留给专业的人来分析和优化.



## 项目实例

### 某小型第三方支付平台压测

#### 需求

##### 业务背景:

公司准备上线一个新的第三方支付平台网站, 用户基本没有, 全靠公司上头的集团在内部员工中推广...此外集团还在某城市有一定的资源, 能借助那些资源在这一个城市做一点推广. 但总之用户数最多也就是几千到一两万左右, 其中同时在线的用户, 那就估计顶多几百.

#### 设计思路

##### 场景设计策略: 

只打算做静态测试, 基线测试和性能测试

##### 业务场景选择: 

其它接口都不测, 只测登录和支付

##### 服务端监控: 

由运维使用商业监控软件负责, 压测全程运维肉眼观察.(后来因为该项目买的服务器过于高端, 服务器硬件全程无压力, 服务器买的过于高端据说是为了把集团给的钱先用掉, 以免来年降低预算.)

脚本检查点:

只看表示登录成功和支付成功的字段的值

数据准备:

预先写脚本注册了几百个账号, 然后把账号和密码写在文本里, 通过参数化传给jmeter.

脚本:

用jmeter花5分钟时间录的.录下来去掉那些多余的无关请求, 改一下参数改成从文本里读.然后加个检查点.

#### 工具选型

jmeter, 理由: 纯http接口, 简单无脑

#### 遇到的问题和总结

我的第一个压测项目, 第一次压静态测试直接挂了, 然后开发修, 修不好, 找硬件技术支持一起修. 修好了.第二天, 低负载性能测试时就出了错. 同时服务端监控显示毫无压力. 架构师估计问题在java web 服务器, 然后开发修, 修好完事了. 具体啥原因不知道, 赶鸭子上架第一次.

### 某第三方artifactory服务器上传下载大文件压测

#### 需求

##### 业务背景:

项目属于某devops项目的子项目, 打算使用某个第三方artifactory服务器. 这个服务器用来存放build踹的jar包及其依赖. 此外, 这个服务器后台用了某个第三方云平台的存储技术. 需求中的大文件指用户同时上传和下载1GB以上大小的大量文件

```mermaid
graph LR
A(用户文件) -->B(待测服务器) -->C(云平台存储)
```

#### 设计思路

##### 场景设计策略:

只打算做基线测试和性能测试

##### 业务场景选择:

总共两个接口, 一个上传一个下载

##### 服务端监控:

系统级监控分两块, 一块由云平台提供, 云平台自带服务端监控, 另一块, 我自己登录到待测服务器上, 敲民营展示当前的系统上的http连接数, 因为上传下载都是用http协议传文件.

还不够, 还要应用级监控, 通过我自己登录到待测服务器上, 打开待测应用到日志文件的方式, 观察其中日志是否报错.

#### 工具选型

shell脚本直接做并发.

因为业务是大文件上传下载, 慢的很, 根本不需要什么精确的高并发, 业务上我们也只要支持到最多100个用户同时上传下载大文件, 我每个脚本做10个进程, 然后搞10台负载机来模拟这100个用户.

##### 为什么不用jmeter?

根本没必要, 首先它只有两个http接口, 每次还只要测1个, 然后jmeter这么麻烦, 我只要传个文件而已,犯不上搞个图形界面工具弄脚本

#### 遇到的问题和总结

一开始忘了做md5校验. 脚本上要做md5确认来确保上传或下载真的成功且完整, 还要搞并发, 因此shell脚本后面有点复杂了.

一开始没意识到瓶颈上负载机的存储容量, 搞得负载机硬盘太小, 后来加大了.

一开始第一次搞大文件就失败了, 然后查待测软件服务端日志, 查第三方服务器的相关博客, 发现它后台是用tomcat服务器, 于是再ssh登录到待测服务器去修改tomcat配置, 把jvm改大, 把模式改成支持并发的模式, 再把这个第三方服务器自己的后台配置里关于如何使用云存储的配置做了修改, 把配置改大.

然后就可以了, 主要优化点都在待测服务器的服务端配置上.

### 某数据库百万级数据同步性能测试

#### 需求

##### 业务背景:

某公司在某国有大型数据库集群内有288万条数据, 且数据在不断变化, 在跨国大洋的另一个国家有用户要访问这些数据, 因此设计了一个本地数据库, 采用一次性同步+后续实时同步的方案来完成数据同步.

```mermaid
graph LR
A(某国用户) -->B(某国的数据库) -->C(隔海的数据库)
```

#### 设计思路

##### 场景设计策略:

基线测试, 性能测试(一张小表同步, 一张表同步, 全部同步)、稳定性测试(仅针对实时同步)

##### 业务场景选择:

总共两个业务场景, 一次性同步和实时同步

##### 服务端监控:

我自己写脚本连接到某国数据库上, 反复查询待测表的数据行数并打印时间戳和数据行数, 然后脚本我搞到jenkins上, 我就让它自动监控着, 事后分析jenkins日志即可.

#### 工具选型

首先我不需要jmeter, 数据同步不是由http请求触发的, 一次性数据同步是由我们开发的某应用触发的, 而且只需要出发一次, 所以我直接人肉点一下触发就行了. 当然这个出发我也做成了脚本, 放到jenkins上.

监控也不需要云平台的监控, 因为服务器撑得住, 我只管查一下表里有多少数据就行了, 所以我只写了一个监控脚本放到jenkins上让它自动跑.

#### 遇到的问题和总结

首先源数据库很麻烦, 是oracle, 目标数据库则是postgresql, 同步要通过oracle公司的一个商业工具来做, 而这个工具的配置和使用非常复杂, 安装也麻烦, 而要测这个需求, 必须多少会一点, 所以就要现学, 时间又紧迫.

这个项目的压力生成方式很独特, 是通过对商业同步工具做配置, 配置并发同步进程和每个进程同步文件大小来决定产生的压力大小的. 在压测前期, 常常是直接同步失败, 同步过程卡死. 这是由于测试环境和压测环境的不同, 造成了我和开发在测试环境的准备的脚本在测试环境上能跑, 在压测环境(类似于准生产环境)上就挂掉. 最终我们在压测环境搞了好几周才搞通.

另外这个商业工具做数据同步的机制也很独特. 它是先把数据源从远端同步到本地(目标数据库的本地), 然后从本地数据源把数据插入目标数据库, 我们最初搞的同步280万条数据也就分两步, 第一步同步数据源只花了1小时15分, 而插入数据花了4小时42分, 每秒插入了1657条数据, 当时配置的并发数是5, size是1000M, 当然后续还继续做了优化, 但其实也没太多必要, 因为用户可以接受这个时间.

最后还有个问题是我们在做压测的过程中, 依赖的是第三方云平台的业务发生了更新, 发布了可以直接帮我们简化很多步骤的新功能, 于是我们的项目架构跟着做了修改, 这也影响了压测的进度(体现在环境搭建脚本的更改上)

还有实时数据同步测试采用了半自动化测试的方式来做, 一边在源数据库插入数据, 一边在新数据库用脚本做查询. 半自动化测试, 在性能测试中是经常使用的方法.



# [公众号 性能测试基础](https://mp.weixin.qq.com/s?__biz=MzUyMTM4MzYyMw==&mid=2247483743&idx=1&sn=683d5a74a8e4104775b108477d5f92a5)

主要讲针对服务器端的性能测试，其他代码级性能测试、前端性能测试等属于比较细分的领域，就不说了。

## 性能测试想做什么



## 性能测试的基本流程



## 性能测试的前期准备



## 性能测试的工具及相关学习建议



# [公众号 常见性能测试指标](https://mp.weixin.qq.com/s?__biz=MzUyMTM4MzYyMw==&mid=2247483934&idx=1&sn=56adbe1c86b4dc98a444d8d835eddce6)

## 吞吐量（平均吞吐量）

吞吐量表示待测应用对业务的支持量，以 TPS 或 QPS 为单位，表示每秒能处理的请求数.

有一个很模糊的概念“并发数”, 似乎和吞吐量有关:

比如经理说, 这个系统要支持 2000 并发, 那么这个要怎么理解, 并发和吞吐量是同一个东西吗?

不一定, 并发数可能是:

## （总）并发用户数

同一时间在系统上的用户数量, 这些用户可能分布在不同的功能模块或页面上

## （总）并发请求数

同一时间在系统上的用户同时向服务器做出的请求数量, 这些请求也可能分布在不同的功能模块或页面上.

所以整个时候就问清楚经理, 是2000并发用户数, 还是2000并发请求数, 后续可以根据不同的回答来设计不同的测试场景.

再说一下为什么这里提到了测试场景.

因为在测试一个系统的性能或者说吞吐量时, 离不开具体业务场景. 在解释为什么之前, 先看这个:

## 平均响应时间

一些请求从发起到收到服务端响应所需的时间点平均数.

说下为什么离不开具体业务场景, 请看公式1:
$$
一段时间内的平均吞吐量 = \dfrac{这段时间内的总并发请求数}{这段时间的平均响应时间}
$$


比如获取一个静态图片, 响应时间就短, 那么根据公式1, 单位时间内的请求的平均响应时间越小, 其平均吞吐量就越高. 而如果是请求一个需要服务端做一定计算的资源, 那么响应时间就长. 自然按照公式1, 就会发现吞吐量降低了.

也就是说响应时间和吞吐量成反比, 因此讨论系统的性能时离不开响应时间, 也就离不开具体的业务场景.

在实际测试工作中, 我们会采用逐步加压的方式, 一步一步提高虚拟的总并发用户数, 并观察其响应时间变化, 因为响应时间和吞吐量成反比, 那么我们观察响应时间的时候其实也就是在观察吞吐量的变化.

压力较低时, 吞吐量和虚拟的总并发用户数可能成正比, 当用户数逐步增加上来之后, 可能吞吐量的增加速度会逐渐下降. 这是因为压力上升后, 系统处理请求能力下降, 平均响应时间加长. 直至某一个点开始, 吞吐量不再上升, 反而下降. 这就是系统处理能力的瓶颈了.







## 错误率



## 90% 平均响应时间



## 平均传输带宽





# [公众号 性能测试如何入门](https://mp.weixin.qq.com/s?__biz=MzUyMTM4MzYyMw==&mid=2247484134&idx=1&sn=f1701638258f6169daa9a41e5d317353)

































